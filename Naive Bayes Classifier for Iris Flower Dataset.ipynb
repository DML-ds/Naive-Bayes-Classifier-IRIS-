{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b960347-5e30-415f-abf8-7d1a87d73b21",
   "metadata": {},
   "source": [
    "##  **Naive Bayes Classifier for Iris Flower Dataset**\n",
    "\n",
    "### 1. Cross Validation: Importing the Dataset and Splitting\n",
    "##### Imports the Iris dataset, splits it into training and testing sets (80/20 split), ensuring stratification of classes for balanced representation.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355309dd-a737-4da3-a108-ac6bafb219ce",
   "metadata": {},
   "source": [
    "### 2. Likelihood: Calculating Mean and Standard Deviation\n",
    "##### Computes the mean and standard deviation of each feature across samples belonging to different classes, and defines a Gaussian likelihood function to model the probability distribution of features given each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0f8cbb8-20d2-4c0a-b928-97a1080d621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation for each feature and class\n",
    "num_classes = len(np.unique(y))\n",
    "num_features = X.shape[1]\n",
    "\n",
    "mean_features = np.zeros((num_classes, num_features))\n",
    "std_features = np.zeros((num_classes, num_features))\n",
    "\n",
    "for class_idx in range(num_classes):\n",
    "    X_class = X_train[y_train == class_idx]\n",
    "    mean_features[class_idx] = np.mean(X_class, axis=0)\n",
    "    std_features[class_idx] = np.std(X_class, axis=0)\n",
    "\n",
    "def gaussian_likelihood(x, mean, std):\n",
    "    numerator = np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "    denominator = np.sqrt(2 * np.pi) * std\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106da91c-86fe-437e-b957-38a10f0aed06",
   "metadata": {},
   "source": [
    "### 3. Priori: Calculating Prior Probabilities\n",
    "##### Calculates the prior probabilities of each class based on their frequency in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86cede04-37f3-4b0c-b83c-af9870912904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prior probabilities\n",
    "prior_probabilities = np.bincount(y_train) / len(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1426cb0-1ed9-44ca-b181-62bcce58b08b",
   "metadata": {},
   "source": [
    "### 4. Posterior: Calculating Posterior Probabilities\n",
    "##### Defines a function to compute the posterior probabilities for a given sample using Bayes' theorem, incorporating the Gaussian likelihood and prior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9eb77cde-c677-4d31-b9f3-b2f7b804a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate posterior probabilities for a sample\n",
    "def posterior_probability(sample):\n",
    "    posteriors = []\n",
    "    for class_idx in range(num_classes):\n",
    "        likelihoods = np.prod(gaussian_likelihood(sample, mean_features[class_idx], std_features[class_idx]))\n",
    "        posterior = likelihoods * prior_probabilities[class_idx]\n",
    "        posteriors.append(posterior)\n",
    "    return posteriors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f92b79-1abc-4f3b-9339-4f1b751824cf",
   "metadata": {},
   "source": [
    "### 5. Prediction Accuracy\n",
    "##### Utilizes the computed posterior probabilities to predict class labels for the test set and evaluates the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a83c659-3a9a-49a3-821b-f4227b9edb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on test set: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels for the test set\n",
    "y_pred = np.argmax([posterior_probability(sample) for sample in X_test], axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Prediction accuracy on test set: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483b6c4-867b-4d78-a81e-f29f5cc5ddd8",
   "metadata": {},
   "source": [
    "### 6. Generated Samples\n",
    "##### Generates new samples by randomly sampling from the learned Gaussian distributions for each class, providing synthetic data based on the statistical model derived from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be3b44d-8455-4d8f-8c87-ff65ab69e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Samples:\n",
      "Sample 1 (Class: setosa): [5.1343439  3.15981393 1.45926096 0.25261814]\n",
      "Sample 2 (Class: versicolor): [6.42628769 3.41556082 4.35579739 1.34147817]\n",
      "Sample 3 (Class: virginica): [7.43363157 3.08117443 5.98798249 1.96624181]\n",
      "Sample 4 (Class: setosa): [5.06629286 3.50785377 1.41320269 0.2076264 ]\n",
      "Sample 5 (Class: versicolor): [6.35769548 2.93473592 4.10560063 1.38189009]\n",
      "Sample 6 (Class: virginica): [7.19072968 3.14192282 4.85026604 2.29596875]\n",
      "Sample 7 (Class: setosa): [4.89038301 3.06356523 1.58449107 0.4568682 ]\n",
      "Sample 8 (Class: versicolor): [5.90694355 2.55192271 4.19103935 1.17036024]\n",
      "Sample 9 (Class: virginica): [7.17607616 2.87027069 6.0746439  2.09933211]\n",
      "Sample 10 (Class: setosa): [5.09717107 3.43951841 1.54114045 0.37989234]\n",
      "Sample 11 (Class: versicolor): [6.21429528 2.04299191 4.1723595  1.45779168]\n",
      "Sample 12 (Class: virginica): [7.90415849 3.54317674 5.50433225 1.77822531]\n",
      "Sample 13 (Class: setosa): [5.49908669 3.22166542 1.24980828 0.4310175 ]\n",
      "Sample 14 (Class: versicolor): [5.40375197 2.78591043 4.46088074 1.31046458]\n",
      "Sample 15 (Class: virginica): [6.64852534 3.15200787 5.28959694 2.04306979]\n",
      "Sample 16 (Class: setosa): [5.14215048 2.9764909  1.57525109 0.25861565]\n",
      "Sample 17 (Class: versicolor): [5.25690588 3.24875232 4.26672443 1.29086475]\n",
      "Sample 18 (Class: virginica): [6.63840629 2.76318174 6.02248216 2.24139547]\n",
      "Sample 19 (Class: setosa): [5.00131889 2.98883935 1.24773322 0.38369968]\n",
      "Sample 20 (Class: versicolor): [5.96831004 2.37042585 4.25287398 1.77479025]\n",
      "Sample 21 (Class: virginica): [6.08724456 3.17639084 4.98278975 2.61510033]\n",
      "Sample 22 (Class: setosa): [5.37873388 2.67564694 1.3886862  0.26212596]\n",
      "Sample 23 (Class: versicolor): [5.41921611 3.04222258 4.58612453 1.17314773]\n",
      "Sample 24 (Class: virginica): [6.12214289 3.04372595 5.55940942 2.30438216]\n",
      "Sample 25 (Class: setosa): [5.1276192  3.33093821 1.39931378 0.33187211]\n",
      "Sample 26 (Class: versicolor): [5.96608633 2.61520547 4.13122959 1.31202071]\n",
      "Sample 27 (Class: virginica): [6.6842515  3.11783977 5.60869785 2.09471966]\n",
      "Sample 28 (Class: setosa): [4.82272556 3.88675539 1.54061685 0.07698594]\n",
      "Sample 29 (Class: versicolor): [6.71891778 2.31895241 4.34127655 1.28731627]\n",
      "Sample 30 (Class: virginica): [6.94850124 3.626587   5.60130313 2.25815625]\n"
     ]
    }
   ],
   "source": [
    "# Generate new samples based on learned distributions\n",
    "def generate_sample(class_idx):\n",
    "    return np.random.normal(mean_features[class_idx], std_features[class_idx])\n",
    "\n",
    "num_samples = 10\n",
    "new_samples = np.array([generate_sample(class_idx) for _ in range(num_samples) for class_idx in range(num_classes)])\n",
    "new_labels = np.array([class_idx for _ in range(num_samples) for class_idx in range(num_classes)])\n",
    "\n",
    "# Print generated samples and their labels\n",
    "print(\"\\nGenerated Samples:\")\n",
    "for i in range(num_samples * num_classes):\n",
    "    class_name = iris.target_names[new_labels[i]]\n",
    "    print(f\"Sample {i+1} (Class: {class_name}):\", new_samples[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f2c2d-22e8-4d01-ab5d-6ae59647fb84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
